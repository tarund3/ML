{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /Users/tarundamodaran/anaconda3/lib/python3.10/site-packages (8.1.5)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/tarundamodaran/anaconda3/lib/python3.10/site-packages (from ipywidgets) (8.10.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/tarundamodaran/anaconda3/lib/python3.10/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /Users/tarundamodaran/anaconda3/lib/python3.10/site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /Users/tarundamodaran/anaconda3/lib/python3.10/site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/tarundamodaran/anaconda3/lib/python3.10/site-packages (from ipywidgets) (5.7.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/tarundamodaran/anaconda3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: pickleshare in /Users/tarundamodaran/anaconda3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/tarundamodaran/anaconda3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: appnope in /Users/tarundamodaran/anaconda3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: decorator in /Users/tarundamodaran/anaconda3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: backcall in /Users/tarundamodaran/anaconda3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: stack-data in /Users/tarundamodaran/anaconda3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/tarundamodaran/anaconda3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.30 in /Users/tarundamodaran/anaconda3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.36)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/tarundamodaran/anaconda3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/tarundamodaran/anaconda3/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/tarundamodaran/anaconda3/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/tarundamodaran/anaconda3/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: executing in /Users/tarundamodaran/anaconda3/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /Users/tarundamodaran/anaconda3/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /Users/tarundamodaran/anaconda3/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six in /Users/tarundamodaran/anaconda3/lib/python3.10/site-packages (from asttokens->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade ipywidgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points: 756\n",
      "Sample prices: [[75.08750153]\n",
      " [74.35749817]\n",
      " [74.94999695]\n",
      " [74.59750366]\n",
      " [75.79750061]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = yf.download(\"AAPL\", start=\"2020-01-01\", end=\"2023-01-01\", interval=\"1d\")\n",
    "\n",
    "prices = df['Close'].values\n",
    "\n",
    "print(\"Number of data points:\", len(prices))\n",
    "print(\"Sample prices:\", prices[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(prices) * 0.7)\n",
    "val_size   = int(len(prices) * 0.2)\n",
    "test_size  = len(prices) - train_size - val_size\n",
    "\n",
    "train_data = prices[:train_size]\n",
    "val_data   = prices[train_size:train_size+val_size]\n",
    "test_data  = prices[train_size+val_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, lookback=20):\n",
    "        self.data = data\n",
    "        self.lookback = lookback\n",
    "        self.size = len(data) - lookback\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx : idx + self.lookback]  # shape (lookback,)\n",
    "        y = self.data[idx + self.lookback]        # single value\n",
    "        x = torch.tensor(x, dtype=torch.float32)  # => shape [lookback]\n",
    "        y = torch.tensor(y, dtype=torch.float32)\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTimeSeriesModel(nn.Module):\n",
    "    def __init__(self, input_dim=1, hidden_dim=32, num_layers=1):\n",
    "        super(LSTMTimeSeriesModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # input_dim = 1 for univariate time series\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc   = nn.Linear(hidden_dim, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "         # x: [batch_size, seq_len, 1]\n",
    "        out, (hn, cn) = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out.squeeze(-1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input must have 3 dimensions, got 5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 41\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39mfor\u001b[39;00m x_batch, y_batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[1;32m     37\u001b[0m     \u001b[39m# Check shape\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     \u001b[39m# print(\"x_batch shape:\", x_batch.shape)\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 41\u001b[0m     outputs \u001b[39m=\u001b[39m model(x_batch)              \u001b[39m# => [batch_size]\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     loss \u001b[39m=\u001b[39m criterion(outputs, y_batch)\n\u001b[1;32m     43\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[33], line 15\u001b[0m, in \u001b[0;36mLSTMTimeSeriesModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     12\u001b[0m     \u001b[39m# x is [batch_size, seq_len]\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[39m# Convert to [batch_size, seq_len, input_dim]\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39munsqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m     out, (hn, cn) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(x)           \u001b[39m# => out: [batch_size, seq_len, hidden_dim]\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(out[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :])           \u001b[39m# => [batch_size, 1]\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[39mreturn\u001b[39;00m out\u001b[39m.\u001b[39msqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/rnn.py:767\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    763\u001b[0m     \u001b[39m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[1;32m    764\u001b[0m     \u001b[39m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[1;32m    765\u001b[0m     hx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m--> 767\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_forward_args(\u001b[39minput\u001b[39;49m, hx, batch_sizes)\n\u001b[1;32m    768\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    769\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers,\n\u001b[1;32m    770\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/rnn.py:692\u001b[0m, in \u001b[0;36mLSTM.check_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_forward_args\u001b[39m(\u001b[39mself\u001b[39m,  \u001b[39m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m    688\u001b[0m                        \u001b[39minput\u001b[39m: Tensor,\n\u001b[1;32m    689\u001b[0m                        hidden: Tuple[Tensor, Tensor],\n\u001b[1;32m    690\u001b[0m                        batch_sizes: Optional[Tensor],\n\u001b[1;32m    691\u001b[0m                        ):\n\u001b[0;32m--> 692\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_input(\u001b[39minput\u001b[39;49m, batch_sizes)\n\u001b[1;32m    693\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_hidden_size(hidden[\u001b[39m0\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_expected_hidden_size(\u001b[39minput\u001b[39m, batch_sizes),\n\u001b[1;32m    694\u001b[0m                            \u001b[39m'\u001b[39m\u001b[39mExpected hidden[0] size \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    695\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_hidden_size(hidden[\u001b[39m1\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_expected_cell_size(\u001b[39minput\u001b[39m, batch_sizes),\n\u001b[1;32m    696\u001b[0m                            \u001b[39m'\u001b[39m\u001b[39mExpected hidden[1] size \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/rnn.py:201\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    199\u001b[0m expected_input_dim \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m3\u001b[39m\n\u001b[1;32m    200\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim() \u001b[39m!=\u001b[39m expected_input_dim:\n\u001b[0;32m--> 201\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    202\u001b[0m         \u001b[39m'\u001b[39m\u001b[39minput must have \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m dimensions, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    203\u001b[0m             expected_input_dim, \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim()))\n\u001b[1;32m    204\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_size \u001b[39m!=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m    205\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    206\u001b[0m         \u001b[39m'\u001b[39m\u001b[39minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    207\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_size, \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input must have 3 dimensions, got 5"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class LSTMTimeSeriesModel(nn.Module):\n",
    "    def __init__(self, input_dim=1, hidden_dim=32, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc   = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is [batch_size, seq_len]\n",
    "        # Convert to [batch_size, seq_len, input_dim]\n",
    "        x = x.unsqueeze(-1)\n",
    "        out, (hn, cn) = self.lstm(x)           # => out: [batch_size, seq_len, hidden_dim]\n",
    "        out = self.fc(out[:, -1, :])           # => [batch_size, 1]\n",
    "        return out.squeeze(-1)                 # => [batch_size]\n",
    "\n",
    "# Example training loop\n",
    "hidden_dim = 32\n",
    "num_layers = 1\n",
    "learning_rate = 1e-3\n",
    "epochs = 20\n",
    "\n",
    "model = LSTMTimeSeriesModel(input_dim=1, hidden_dim=hidden_dim, num_layers=num_layers)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    running_train_loss = 0.0\n",
    "    \n",
    "    for x_batch, y_batch in train_loader:\n",
    "        # Check shape\n",
    "        # print(\"x_batch shape:\", x_batch.shape)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x_batch)              # => [batch_size]\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_train_loss += loss.item() * x_batch.size(0)\n",
    "    \n",
    "    epoch_train_loss = running_train_loss / len(train_dataset)\n",
    "    train_losses.append(epoch_train_loss)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x_val, y_val in val_loader:\n",
    "            val_outputs = model(x_val)\n",
    "            val_loss = criterion(val_outputs, y_val)\n",
    "            running_val_loss += val_loss.item() * x_val.size(0)\n",
    "    \n",
    "    epoch_val_loss = running_val_loss / len(val_dataset)\n",
    "    val_losses.append(epoch_val_loss)\n",
    "    \n",
    "    print(f\"Epoch [{epoch}/{epochs}], \"\n",
    "          f\"Train Loss: {epoch_train_loss:.4f}, Val Loss: {epoch_val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "For unbatched 2-D input, hx and cx should also be 2-D but got (3-D, 3-D) tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m      6\u001b[0m     \u001b[39mfor\u001b[39;00m x_test, y_test \u001b[39min\u001b[39;00m test_loader:\n\u001b[0;32m----> 7\u001b[0m         y_pred \u001b[39m=\u001b[39m model(x_test)\n\u001b[1;32m      8\u001b[0m         preds\u001b[39m.\u001b[39mappend(y_pred\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy())\n\u001b[1;32m      9\u001b[0m         actuals\u001b[39m.\u001b[39mappend(y_test\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[15], line 20\u001b[0m, in \u001b[0;36mLSTMTimeSeriesModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m h0 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, x\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_dim)\n\u001b[1;32m     18\u001b[0m c0 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, x\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_dim)\n\u001b[0;32m---> 20\u001b[0m out, (hn, cn) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(x, (h0, c0))\n\u001b[1;32m     21\u001b[0m \u001b[39m# Take the last time step's output\u001b[39;00m\n\u001b[1;32m     22\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(out[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :])  \u001b[39m# (batch_size, hidden_dim) -> (batch_size, 1)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/rnn.py:760\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    757\u001b[0m         \u001b[39mif\u001b[39;00m hx[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdim() \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m \u001b[39mor\u001b[39;00m hx[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mdim() \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m    758\u001b[0m             msg \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mFor unbatched 2-D input, hx and cx should \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    759\u001b[0m                    \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39malso be 2-D but got (\u001b[39m\u001b[39m{\u001b[39;00mhx[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdim()\u001b[39m}\u001b[39;00m\u001b[39m-D, \u001b[39m\u001b[39m{\u001b[39;00mhx[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mdim()\u001b[39m}\u001b[39;00m\u001b[39m-D) tensors\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 760\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg)\n\u001b[1;32m    761\u001b[0m         hx \u001b[39m=\u001b[39m (hx[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m), hx[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m))\n\u001b[1;32m    763\u001b[0m \u001b[39m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[1;32m    764\u001b[0m \u001b[39m# the user believes he/she is passing in.\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: For unbatched 2-D input, hx and cx should also be 2-D but got (3-D, 3-D) tensors"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "preds = []\n",
    "actuals = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_test, y_test in test_loader:\n",
    "        y_pred = model(x_test)\n",
    "        preds.append(y_pred.detach().numpy())\n",
    "        actuals.append(y_test.detach().numpy())\n",
    "\n",
    "preds = np.concatenate(preds)\n",
    "actuals = np.concatenate(actuals)\n",
    "\n",
    "# Plot predictions vs. actual\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(actuals, label='Actual')\n",
    "plt.plot(preds, label='Predicted')\n",
    "plt.title('Test Data Predictions')\n",
    "plt.xlabel('Time Step (sliding window index)')\n",
    "plt.ylabel('Closing Price')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
